<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Lecturer @ CUET">
    <meta name="keywords" content="website, khaleda, sathi, khaleda akhter, khaleda akhter sathi, shathi">
    <meta name="author" content="Khaleda Akhter Sathi">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    <link rel="KA-1" sizes="180x180" href="images/nicons/KA-1.JPG">
    <link rel="KA-2" type="image/png" sizes="32x32" href="images/nicons/KA-2.JPG">
    <link rel="KA-3" type="image/png" sizes="16x16" href="images/nicons/KA-3.JPG">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
    <link rel="stylesheet" href="assets/style.css">
  <title>Khaleda Akhter Sathi</title>
  </head>
  <body>
    <div class="container pb-5 allstuffp">
        <div class="row pt-5 allstuff">
            <div class="col-md-3 pt-5">
                <div class="fixed-posi">
                <p class="name pb-10"><b>Khaleda Akhter Sathi</b></p>
                <img src="images/sathi.jpg" class="profilepic pt-5 pb-4">
                <div class="pt-5">
                  <a>Lecturer @ CUET </a><br>
                  <a id="icon_email" class="tag had" href="sathi.ete@cuet.ac.bd" target="_blank"><i class="fas fa-envelope"></i>&nbsp; email</a><br>
                  <a id="icon_github" class="tag had" href="https://github.com/khaledaakhter" target="_blank"><i class="had fab fa-github"></i>&nbsp; github</a><br>
                  <a id="icon_gscholar" class="tag had" href="https://scholar.google.com/citations?hl=en&user=jYYusJkAAAAJ&view_op=list_works" target="_blank"><i class="fab fa-google"></i>&nbsp; google scholar</a> <br>
                  <a id="icon_orcid" class="tag had" href="https://orcid.org/0000-0003-0031-9284" target="_blank"> <i class="fab fa-orcid"></i>&nbsp; ORCiD</a> <br>
                  <a id="icon_publon" class="tag had" href="https://publons.com/researcher/4467398/khaleda-akhter-sathi/" target="_blank"><i class="fab fa-publon"></i>&nbsp; publon</a> <br>
                  </div>
            </div>
          </div>
          <div class="col-md-8 pt-4 about">
            <p class='header pt-10'><b>Overview</b></p>
            I khaleda Akhter Sathi, currently serving as a Lecturer at Chittagong University of Engineering & Technology (CUET), Bangladesh. <br> <br>
            My primary research interest is somewhere lies in between Deep Learning and Brain Stimulation. Particularly, the endeavor includes developing 
            the database related to the magnetic neuromodulation technique (i.e., TMS) as well as building the computational model to predict its outcome 
            prior to treating neurological disorders such as Parkinson's, Depression, Epilepsy, Traumatic Brain Injury, etc.<br><br>
            Besides, the secondary interest intersects between Computer Vision and Deep Learning. Where developing new computational models is concerned 
            with focusing on dataset features for performing the classification task, particularly in Medical Imaging.</p>
            <p class="header pt-5"><b>Research Interests</b></p>
            <div class="details">
            <p><span class="bullet">-</span> Deep Learning.<br>
            <span class="bullet">-</span> Brain Stimulation.<br>
            <span class="bullet">-</span> Computer Vision.<br></p>
            <span class="bullet">-</span> Medical Imaging.<br></p> 
            </div>
                 <p class="header pt-5"><b>Publications</b></p>
                 <div class="py-2">
                   <p class="paper my-2 pl-2">
                       <span class="papertitle">Attention-assisted hybrid 1D CNN-BiLSTM model for predicting electric field induced by transcranial magnetic stimulation coil</span><br>
                       Khaleda Akhter Sathi*, Md. Kamal Hosain, Md.Azad Hossain, Abbas Z. Kouzani</span><br>
                       <span class="Journal"><a class="journalshort" href="https://www.nature.com/srep/">Scientific Reports 2023 </a> | Nature Portfolio </span><br>
                    
                       <a class="tag" href="https://arxiv.org/pdf/2004.09095.pdf" target="_blank">pdf</a><span class="tagsep">|</span>
                       <a class="tag" href="https://arxiv.org/abs/2004.09095" target="_blank">abstract</a><span class="tagsep">|</span>
                       <a class="tag" href="cites/acl2020.bib" target="_blank">cite</a><span class="tagsep">|</span>
                       <a class="tag" href="https://microsoft.github.io/linguisticdiversity/" target="_blank">website</a>
                   </p>
                 </div>
                 <div class="py-2">
                    <p class="paper my-2 pl-2">
                        <span class="papertitle">Resource Consumption and Radiation Tolerance Assessment for Data Analysis Algorithms Onboard Spacecraft</span><br>
                        <span class="defaultauthor">Gary Doran, </span><span class="thisauthor">Ameya Daigavane</span><span class="defaultauthor"> and Kiri Wagstaff</span><br>
                        <span class="conf"><a class="confshort" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7">IEEE Transactions on Aerospace and Electronic Systems</a>
                        <br>

                        <a class="tag" href="https://ieeexplore.ieee.org/document/9763454" target="_blank">article</a>
                        <span class="tagsep">|</span>
                        <a class="tag" href="https://github.com/JPLMLIA/libeos" target="_blank">code</a>
                    </p>
                 </div>
                 <div class="py-2">
                    <p class="paper my-2 pl-2">
                        <span class="papertitle">Integrating Deep Learning and Unbiased Automated High-Content Screening to Identify Complex Disease Signatures in Human Fibroblasts</span><br>
                        <span class="defaultauthor">Lauren Schiff, Bianca Migliori, et al</span><br>
                        <span class="conf"><a class="confshort" href="https://www.nature.com/ncomms/">Nature Communications</a>
                        <br>

                        <a class="tag" href="https://www.nature.com/articles/s41467-022-28423-4" target="_blank">article</a>
                    </p>
                 </div>
                 <div class="pt-5">
						     <b>Miscellaneous</b><be>
						        <span class="authors">Resources:
							            <a href="assets/UW_PhD_SOP_Public.pdf" target="_blank">My PhD Statement</a>,
							            <a href="https://github.com/SebastinSanty/Just-Another-Research-CV" target="_blank">CV Template</a>
						        </span><br>
					       </div>
          </div>
            	<script>
				        paper_count = 0

				        function add_paper(title, authors, conference, link, bib, abstract, arxiv_link, code, data, slides, talk, msg) {
				            list_entry = "<li style=\"font-size:15px\">"
				            if (link != null)
				                list_entry += "<a href=\"" + link + "\">"
				            list_entry += "<b>" + title + "</b>"
				            if (link != null)
				                list_entry += "</a>"
				            list_entry += "<br>" + authors + "<br>" + conference + "</li>"

				            if (bib != null) {
				                list_entry += "<div id=\"bib" + paper_count + "\" style=\"display:none\">" + bib + "</div>"
				                list_entry += "<a href=\"javascript:copy(div" + paper_count + ",bib" + paper_count + ")\"> <span class=\"btn-sm btn-info\">bib</span></a>"
				            }

				            if (abstract != null) {
				                list_entry += "<div id=\"abstract" + paper_count + "\" style=\"display:none\">" + abstract + "</div>"
				                list_entry += " <a href=\"javascript:copy(div" + paper_count + ",abstract" + paper_count + ")\"> <span class=\"btn-sm btn-info\">abstract</span></a>"
				                // list_entry += " <a target=\"_blank\" href=\"javascript:copy(div" + paper_count + ",abstract" + paper_count + ")\" class=\"btn-sm btn-info\">abstract</a>"
				            }
				            if (arxiv_link != null)
				                list_entry += " <a target=\"_blank\" href=\"" + arxiv_link + "\" class=\"btn-sm btn-info\">arXiv</a>"

				            if (code != null)
				                list_entry += " <a target=\"_blank\" href=\"" + code + "\" class=\"btn-sm btn-info\">code</a>"

				            if (data != null)
				                list_entry += " <a target=\"_blank\" href=\"" + data + "\" class=\"btn-sm btn-info\">data</a>"

				            if (slides != null)
				                list_entry += " <a target=\"_blank\" href=\"" + slides + "\" class=\"btn-sm btn-info\">presentation</a>"

				            if (talk != null)
				                list_entry += " <a target=\"_blank\" href=\"" + talk + "\" class=\"btn-sm btn-info\">talk</a>"

				            list_entry += "<br>"

				            if (msg != null)
				                list_entry += "<i>" + msg + "</i>"

				            list_entry += "<div id=\"div" + paper_count + "\" style=\"font-size:15px\"></div><br>"

				            document.write(list_entry)

				            paper_count += 1
				        }

				        // ---------------------------------- 2022 ------------------------------------------------------------------------------------------------------
				        document.write("<h5>2022</h5>")
				        document.write("<ul style=\"list-style: none;\">")


				        add_paper("End-to-end Case-Based Reasoning for Commonsense Knowledge Base Completion",
				            "Zonglin Yang, <strong>Xinya Du</strong>, Erik Cambria, Claire Cardie", // authors
				            "EACL 2023", // conference
				            "https://w.sentic.net/commonsense-knowledge-base-completion.pdf", // link
				            "@InProceedings{yang2023cbr},<br>" + // bib
				            "&nbsp;&nbsp;&nbsp;title={End-to-end Case-Based Reasoning for Commonsense Knowledge Base Completion},<br>" +
				            "&nbsp;&nbsp;&nbsp;author={Yang, Zonglin and Du, Xinya and Cambria, Erik and Cardie, Claire},<br>" +
				            "&nbsp;&nbsp;&nbsp;booktitle={EACL},<br>" +
				            "&nbsp;&nbsp;&nbsp;year={2023}<br>}",
				            "n/a", // abstract
				            "n/a", // arXiv_link
				            // "https://github.com/xinyadu/RGQA", // code
				            // "abc", // data
				            // "abc" // pre
				        )

				        add_paper("Logical Entity Representation in Knowledge-Graphs for Differentiable Rule Learning",
				            "Chi Han, Qizheng He, Charles Yu, <b>Xinya Du</b>, Hanghang Tong, Heng Ji", // authors
				            "ICLR 2023", // conference
				            "https://arxiv.org/pdf/2211.07067.pdf", // link
				            "@InProceedings{yang2023cbr},<br>" + // bib
				            "&nbsp;&nbsp;&nbsp;title={Logical Entity Representation in Knowledge-Graphs for Differentiable Rule Learning},<br>" +
				            "&nbsp;&nbsp;&nbsp;author={Han, Chi et al},<br>" +
				            "&nbsp;&nbsp;&nbsp;booktitle={ICLR},<br>" +
				            "&nbsp;&nbsp;&nbsp;year={2023}<br>}",
				            "Probabilistic logical rule learning has shown great strength in logical rule mining and knowledge graph completion. It learns logical rules to predict missing edges by reasoning on existing edges in the knowledge graph. However, previous efforts have largely been limited to only modeling chain-like Horn clauses such as R1(x; z) ^ R2(z; y) ) H(x; y). This formulation overlooks additional contextual information from neighboring sub-graphs of entity variables x, y and z. Intuitively, there is a large gap here, as local sub-graphs have been found to provide important information for knowledge graph completion. Inspired by these observations, we propose Logical Entity RePresentation (LERP) to encode contextual information of entities in the knowledge graph. A LERP is designed as a vector of probabilistic logical functions on the entity’s neighboring sub-graph. It is an interpretable representation while allowing for differentiable optimization. We can then incorporate LERP into probabilistic logical rule learning to learn more expressive rules. Empirical results demonstrate that with LERP, our model outperforms other rule learning methods in knowledge graph completion and is comparable or even superior to state-of-the-art black-box methods. Moreover, we find that our model can discover a more expressive family of logical rules. LERP can also be further combined with embedding learning methods like TransE to make it more interpretable.", // abstract
				            "https://openreview.net/forum?id=JdgO-ht1uTN", // arXiv_link
				            // "https://github.com/xinyadu/RGQA", // code
				            // "abc", // data
				            // "abc" // pre
				        )

				        add_paper("Retrieval-Augmented Generative Question Answering for Event Argument Extraction",
				            "<b>Xinya Du</b> and Heng Ji", // authors
				            "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP)", // conference
				            "https://arxiv.org/pdf/2211.07067.pdf", // link
				            "@InProceedings{du2022retrieval},<br>" + // bib
				            "&nbsp;&nbsp;&nbsp;title={Retrieval-Augmented Generative Question Answering for Event Argument Extraction},<br>" +
				            "&nbsp;&nbsp;&nbsp;author={Du, Xinya and Ji, Heng},<br>" +
				            "&nbsp;&nbsp;&nbsp;booktitle={EMNLP},<br>" +
				            "&nbsp;&nbsp;&nbsp;year={2022}<br>}",
				            "Event argument extraction has long been studied as a sequential prediction problem with extractive-based methods, tackling each argument in isolation. Although recent work proposes generation-based methods to capture cross-argument dependency, they require generating and post-processing a complicated target sequence (template). Motivated by these observations and recent pretrained language models’ capabilities of learning from demonstrations. We propose a retrieval-augmented generative QA model (R-GQA) for event argument extraction. It retrieves the most similar QA pair and augments it as prompt to the current example’s context, then decodes the arguments as answers. Our approach outperforms substantially prior methods across various settings (i.e. fully supervised, domain transfer, and fewshot learning). Finally, we propose a clusteringbased sampling strategy (JointEnc) and conduct a thorough analysis of how different strategies influence the few-shot learning performance.", // abstract
				            "https://arxiv.org/abs/2211.07067", // arXiv_link
				            "https://github.com/xinyadu/RGQA", // code
				            // "abc", // data
				            // "abc" // pre
				        )
				        add_paper("Dynamic Global Memory for Document-level Argument Extraction",
				            "<b>Xinya Du</b>, Sha Li, Heng Ji", // authors
				            "Association for Computational Linguistics and the International Joint Conference on Natural Language Processing (ACL-IJCNLP) 2022", // conference
				            "https://aclanthology.org/2022.acl-long.361/", // link
				            "@InProceedings{du2022dynamic,<br>" + // bib
				            "&nbsp;&nbsp;&nbsp;title={Dynamic Global Memory for Document-level Argument Extraction},<br>" +
				            "&nbsp;&nbsp;&nbsp;author={Du, Xinya and Li, Sha and Ji, Heng},<br>" +
				            "&nbsp;&nbsp;&nbsp;booktitle={Association for Computational Linguistics (ACL)},<br>" +
				            "&nbsp;&nbsp;&nbsp;year={2022}<br>}",
				            "Extracting informative arguments of events from news articles is a challenging problem in information extraction, which requires a global understanding of each document. While recent work on document-level extraction has gone beyond single-sentence and increased the cross-sentence inference capability of end-to-end models, they are still restricted by certain input sequence length constraints and usually ignore the global context between events. To tackle this issue, we introduce a new global neural generation-based framework for document-level event argument extraction by constructing a document memory store to record the contextual event information and leveraging it to implicitly and explicitly help with decoding of arguments for later events. Empirical results show that our framework outperforms prior methods substantially and it is more robust to adversarially annotated examples with our constrained decoding design.", // abstract
				            null, // arXiv_link
				            "https://github.com/xinyadu/memory_docie", // code
				            // "abc", // data
				            // "abc" // pre
				        )

				        add_paper("Automatic Error Analysis for Document-level Information Extraction",
				            "Aliva Das<sup>*</sup>, <b>Xinya Du</b><sup>*</sup>, Barry Wang<sup>*</sup>, Jiayuan Gu, Kejian Shi, Thomas Porter, Claire Cardie", // authors
				            "ACL 2022", // conference
				            "https://aclanthology.org/2022.acl-long.274.pdf", // link
				            "@InProceedings{das2022error,<br>" + // bib
				            "&nbsp;&nbsp;&nbsp;title={Automatic Error Analysis for Document-level Information Extraction},<br>" +
				            "&nbsp;&nbsp;&nbsp;author={Das, Aliva and Du, Xinya  and Wang, Barry  and Shi, Kejian  and Gu, Jiayuan  and Porter, Thomas  and Cardie, Claire,<br>" +
				            "&nbsp;&nbsp;&nbsp;booktitle={Association for Computational Linguistics (ACL)},<br>" +
				            "&nbsp;&nbsp;&nbsp;year={2022}<br>}",
				            "Document-level information extraction (IE) tasks have recently begun to be revisited in earnest using the end-to-end neural network techniques that have been successful on their sentence-level IE counterparts. Evaluation of the approaches, however, has been limited in a number of dimensions. In particular, the precision/recall/F1 scores typically reported provide few insights on the range of errors the models make. We build on the work of Kummerfeld and Klein (2013) to propose a transformation-based framework for automating error analysis in document-level event and (N-ary) relation extraction. We employ our framework to compare two state-of-the-art document-level template-filling approaches on datasets from three domains; and then, to gauge progress in IE since its inception 30 years ago, vs. four systems from the MUC-4 (1992) evaluation.", // abstract
				            null, // arXiv_link
				            "https://github.com/icejinx33/auto-err-template-fill", // code
				        )
				        add_paper("RESIN-11: Schema-guided Event Prediction for 11 Newsworthy Scenarios",
				            "<b>Xinya Du</b>, Zixuan Zhang, Sha Li, Ziqi Wang, Pengfei Yu, Hongwei Wang, Tuan Manh Lai, Xudong Lin, Iris Liu, Ben Zhou, Haoyang Wen, Manling Li, Darryl Hannan, Jie Lei, Hyounghun Kim, Rotem Dror, Haoyu Wang, Michael Regan, Qi Zeng, Qing Lyu, Charles Yu, Carl Edwards, Xiaomeng Jin, Yizhu Jiao, Ghazaleh Kazeminejad, Zhenhailong Wang, Chris Callison-Burch, Carl Vondrick, Mohit Bansal, Dan Roth, Jiawei Han, Shih-Fu Chang, Martha Palmer, Heng Ji", // authors
				            "NAACL 2022 (demo)", // conference
				            "https://blender.cs.illinois.edu/paper/resin2022.pdf", // link
				            null, //bib
				            null, //abs
				            null, //arxiv
				            "https://github.com/RESIN-KAIROS/RESIN-11",//code
				            null, //data
				            "http://18.221.187.153:11000/kairos",  //pre
				        )
				        document.write("</ul>")


				        // ---------------------------------- 2021 ------------------------------------------------------------------------------------------------------
				        document.write("<h5>2021</h5>")
				        document.write("<ul style=\"list-style: none;\">")
				        add_paper("Towards More Intelligent Extraction of Information from Documents",
				            "<b>Xinya Du</b>", // authors
				            "PhD Dissertation, Cornell University", // conference
				            "https://search.proquest.com/openview/ff090eb702b98c8e4562865ddb5e7f81/1?pq-origsite=gscholar&cbl=18750&diss=y", // link
						    "@article{du2021towards,<br>" +
 							"&nbsp;&nbsp;&nbsp;title={Towards More Intelligent Extraction of Information from Documents},<br>" + 
  						    "&nbsp;&nbsp;&nbsp;author={Du, Xinya},<br>" + 
  						    "&nbsp;&nbsp;&nbsp;year={2021},<br>" + 
  						    "&nbsp;&nbsp;&nbsp;school={Cornell University}<br>}",
				        )
				        add_paper("Template Filling with Generative Transformers",
				            "<b>Xinya Du</b>, Alexander M. Rush, Claire Cardie", // authors
				            "NAACL 2021 (short)", // conference
				            "https://aclanthology.org/2021.naacl-main.70", // link
				            null,
				            // "@InProceedings{du2022dynamic,<br>" + // bib
				            // "&nbsp;&nbsp;&nbsp;title={Dynamic Global Memory for Document-level Argument Extraction},<br>" +
				            // "&nbsp;&nbsp;&nbsp;author={Du, Xinya and Li, Sha and Ji, Heng},<br>" +
				            // "&nbsp;&nbsp;&nbsp;booktitle={Association for Computational Linguistics (ACL)},<br>" +
				            // "&nbsp;&nbsp;&nbsp;year={2022}<br>}",
				            "Template filling is generally tackled by a pipeline of two separate supervised systems – one for role-filler extraction and another for template/event recognition. Since pipelines consider events in isolation, they can suffer from error propagation. We introduce a framework based on end-to-end generative transformers for this task (i.e., GTT). It naturally models the dependence between entities both within a single event and across the multiple events described in a document. Experiments demonstrate that this framework substantially outperforms pipeline-based approaches, and other neural end-to-end baselines that do not model between-event dependencies. We further show that our framework specifically improves performance on documents containing multiple events.", // abstract
				            null, // arXiv_link
				            "https://github.com/xinyadu/gtt", // code
				        )
				        add_paper("GRIT: Generative Role-filler Transformers for <strong>Document-level</strong> Event Entity Extraction",
				            "<b>Xinya Du</b>, Alexander M. Rush, Claire Cardie", // authors
				            "EACL 2021", // conference
				            "https://aclanthology.org/2021.eacl-main.52", // link
				            null,
				            // "@InProceedings{du2022dynamic,<br>" + // bib
				            // "&nbsp;&nbsp;&nbsp;title={Dynamic Global Memory for Document-level Argument Extraction},<br>" +
				            // "&nbsp;&nbsp;&nbsp;author={Du, Xinya and Li, Sha and Ji, Heng},<br>" +
				            // "&nbsp;&nbsp;&nbsp;booktitle={Association for Computational Linguistics (ACL)},<br>" +
				            // "&nbsp;&nbsp;&nbsp;year={2022}<br>}",
				            "We revisit the classic problem of document-level role-filler entity extraction (REE) for template filling. We argue that sentence-level approaches are ill-suited to the task and introduce a generative transformer-based encoder-decoder framework (GRIT) that is designed to model context at the document level: it can make extraction decisions across sentence boundaries; is implicitly aware of noun phrase coreference structure, and has the capacity to respect cross-role dependencies in the template structure. We evaluate our approach on the MUC-4 dataset, and show that our model performs substantially better than prior work. We also show that our modeling choices contribute to model performance, e.g., by implicitly capturing linguistic knowledge such as recognizing coreferent entity mentions.", // abstract
				            null, // arXiv_link
				            "https://github.com/xinyadu/grit_doc_event_entity", // code
				        )
				        add_paper("Few-shot Intent Classification and Slot Filling with Retrieved Examples",
				            "Dian Yu, Luheng He, Yuan Zhang, <strong>Xinya Du</strong>, Panupong Pasupat, Qi Li", // authors
				            "NAACL 2021", // conference
				            "https://aclanthology.org/2021.naacl-main.59/", // link
				            null,
				            // "@InProceedings{du2022dynamic,<br>" + // bib
				            // "&nbsp;&nbsp;&nbsp;title={Dynamic Global Memory for Document-level Argument Extraction},<br>" +
				            // "&nbsp;&nbsp;&nbsp;author={Du, Xinya and Li, Sha and Ji, Heng},<br>" +
				            // "&nbsp;&nbsp;&nbsp;booktitle={Association for Computational Linguistics (ACL)},<br>" +
				            // "&nbsp;&nbsp;&nbsp;year={2022}<br>}",
				            "Few-shot learning arises in important practical scenarios, such as when a natural language understanding system needs to learn new semantic labels for an emerging, resource-scarce domain. In this paper, we explore retrieval-based methods for intent classification and slot filling tasks in few-shot settings. Retrieval-based methods make predictions based on labeled examples in the retrieval index that are similar to the input, and thus can adapt to new domains simply by changing the index without having to retrain the model. However, it is non-trivial to apply such methods on tasks with a complex label space like slot filling. To this end, we propose a span-level retrieval method that learns similar contextualized representations for spans with the same label via a novel batch-softmax objective. At inference time, we use the labels of the retrieved spans to construct the final structure with the highest aggregated score. Our method outperforms previous systems in various few-shot settings on the CLINC and SNIPS benchmarks.", // abstract
				            "https://arxiv.org/abs/2104.05763", // arXiv_link
				            // "https://github.com/xinyadu/grit_doc_event_entity", // code
				        )
				        add_paper("QA-Driven Zero-shot Slot Filling with Weak Supervision Pretraining",
				            "<strong>Xinya Du</strong>, Luheng He, Qi Li, Dian Yu, Panupong Pasupat and Yuan Zhang", // authors
				            "ACL 2021", // conference
				            "https://aclanthology.org/2021.acl-short.83.pdf", // link
				            null,
				            // "@InProceedings{du2022dynamic,<br>" + // bib
				            // "&nbsp;&nbsp;&nbsp;title={Dynamic Global Memory for Document-level Argument Extraction},<br>" +
				            // "&nbsp;&nbsp;&nbsp;author={Du, Xinya and Li, Sha and Ji, Heng},<br>" +
				            // "&nbsp;&nbsp;&nbsp;booktitle={Association for Computational Linguistics (ACL)},<br>" +
				            // "&nbsp;&nbsp;&nbsp;year={2022}<br>}",
				            "Slot-filling is an essential component for build- ing task-oriented dialog systems. In this work, we focus on the zero-shot slot-filling problem, where the model needs to predict slots and their values, given utterances from new do- mains without training on the target domain. Prior methods directly encode slot descrip- tions to generalize to unseen slot types. How- ever, raw slot descriptions are often ambigu- ous and do not encode enough semantic in- formation, limiting the models’ zero-shot ca- pability. To address this problem, we intro- duce QA-driven slot filling (QASF), which ex- tracts slot-filler spans from utterances with a span-based QA model. We use a linguistically motivated questioning strategy to turn descrip- tions into questions, allowing the model to gen- eralize to unseen slot types. Moreover, our QASF model can benefit from weak supervi- sion signals from QA pairs synthetically gen- erated from unlabeled conversations. Our full system substantially outperforms baselines by over 5% on the SNIPS benchmark.", // abstract
				            // "https://arxiv.org/abs/2104.05763", // arXiv_link
				            // "https://github.com/xinyadu/grit_doc_event_entity", // code
				        )

				        document.write("</ul>")

						// ---------------------------------- 2020 ------------------------------------------------------------------------------------------------------
				        document.write("<h5>2020</h5>")
				        document.write("<ul style=\"list-style: none;\">")
				        add_paper("Event Extraction by Answering (Almost) Natural <strong>Questions</strong>",
				            "<b>Xinya Du</b>, Claire Cardie", // authors
				            "EMNLP 2020", // conference
				            "https://aclanthology.org/2020.emnlp-main.49/", // link
				            // null,
				            "@Inproceedings{du2022eeqa,<br>" + // bib
				            "&nbsp;&nbsp;&nbsp;title={Event Extraction by Answering (Almost) Natural Questions},<br>" +
				            "&nbsp;&nbsp;&nbsp;author={Du, Xinya and Cardie, Claire},<br>" +
				            "&nbsp;&nbsp;&nbsp;booktitle={EMNLP)},<br>" +
				            "&nbsp;&nbsp;&nbsp;year={2022}<br>}",
				            "The problem of event extraction requires detecting the event trigger and extracting its corresponding arguments. Existing work in event argument extraction typically relies heavily on entity recognition as a preprocessing/concurrent step, causing the well-known problem of error propagation. To avoid this issue, we introduce a new paradigm for event extraction by formulating it as a question answering (QA) task that extracts the event arguments in an end-to-end manner. Empirical results demonstrate that our framework outperforms prior methods substantially; in addition, it is capable of extracting event arguments for roles not seen at training time (i.e., in a zero-shot learning setting).", // abstract
				            "https://arxiv.org/abs/2004.13625", // arXiv_link
				            "https://github.com/xinyadu/eeqa", // code
				        )
				        add_paper("Improving Event Duration Prediction via Time-aware Pre-training",
				            "Zonglin Yang, <strong>Xinya Du</strong>, Alexander Rush, Claire Cardie", // authors
				            "EMNLP 2020 (Findings)", // conference
				            "https://aclanthology.org/2020.findings-emnlp.302.pdf", // link
				            null,
				            // "@Inproceedings{du2022eeqa,<br>" + // bib
				            // "&nbsp;&nbsp;&nbsp;title={Dynamic Global Memory for Document-level Argument Extraction},<br>" +
				            // "&nbsp;&nbsp;&nbsp;author={Du, Xinya and Cardie, Claire},<br>" +
				            // "&nbsp;&nbsp;&nbsp;booktitle={EMNLP)},<br>" +
				            // "&nbsp;&nbsp;&nbsp;year={2022}<br>}",
				            "End-to-end models in NLP rarely encode external world knowledge about length of time. We introduce two effective models for duration prediction, which incorporate external knowledge by reading temporal-related news sentences (time-aware pre-training). Specifically, one model predicts the range/unit where the duration value falls in (R-PRED); and the other predicts the exact duration value (E-PRED). Our best model – E-PRED, substantially outperforms previous work, and captures duration information more accurately than R-PRED. We also demonstrate our models are capable of duration prediction in the unsupervised setting, outperforming the baselines.", // abstract
				            // "https://arxiv.org/abs/2004.13625", // arXiv_link
				            // "https://github.com/xinyadu/eeqa", // code
				        )
				        add_paper("Document-Level <em>Event Role Filler</em> Extraction Using Multi-Granularity Contextualized Encoding",
				            "<strong>Xinya Du</strong>, Claire Cardie", // authors
				            "ACL 2020", // conference
				            "https://aclanthology.org/2020.acl-main.714/", // link
				            // null,
				            "@Inproceedings{du2020document,<br>" + // bib
				            "&nbsp;&nbsp;&nbsp;title={Document-Level Event Role Filler Extraction Using Multi-Granularity Contextualized Encoding},<br>" +
				            "&nbsp;&nbsp;&nbsp;author={Du, Xinya and Cardie, Claire},<br>" +
				            "&nbsp;&nbsp;&nbsp;booktitle={ACL},<br>" +
				            "&nbsp;&nbsp;&nbsp;year={2020}<br>}",
				            "Few works in the literature of event extraction have gone beyond individual sentences to make extraction decisions. This is problematic when the information needed to recognize an event argument is spread across multiple sentences. We argue that document-level event extraction is a difficult task since it requires a view of a larger context to determine which spans of text correspond to event role fillers. We first investigate how end-to-end neural sequence models (with pre-trained language model representations) perform on document-level role filler extraction, as well as how the length of context captured affects the models’ performance. To dynamically aggregate information captured by neural representations learned at different levels of granularity (e.g., the sentence- and paragraph-level), we propose a novel multi-granularity reader. We evaluate our models on the MUC-4 event extraction dataset, and show that our best system performs substantially better than prior work. We also report findings on the relationship between context length and neural model performance on the task.", // abstract
				            null,
				            // "https://arxiv.org/abs/2004.13625", // arXiv_link
				            "https://github.com/xinyadu/doc_event_role", // code
				        )
				        add_paper("Leveraging Structured Metadata for Improving Question Answering on the Web",
				            "<strong>Xinya Du</strong>, Adam Fourney, Robert Sim, Paul Bennett, Claire Cardie, Ahmed Hassan Awadallah", // authors
				            "AACL 2020", // conference
				            "https://aclanthology.org/2020.aacl-main.55/", // link
				            null,
				            // "@Inproceedings{du2020document,<br>" + // bib
				            // "&nbsp;&nbsp;&nbsp;title={Document-Level Event Role Filler Extraction Using Multi-Granularity Contextualized Encoding},<br>" +
				            // "&nbsp;&nbsp;&nbsp;author={Du, Xinya and Cardie, Claire},<br>" +
				            // "&nbsp;&nbsp;&nbsp;booktitle={ACL},<br>" +
				            // "&nbsp;&nbsp;&nbsp;year={2020}<br>}",
				            "We show that leveraging metadata information from web pages can improve the performance of models for answer passage selection/reranking. We propose a neural passage selection model that leverages metadata information with a fine-grained encoding strategy, which learns the representation for metadata predicates in a hierarchical way. The models are evaluated on the MS MARCO (Nguyen et al., 2016) and Recipe-MARCO datasets. Results show that our models significantly outperform baseline models, which do not incorporate metadata. We also show that the fine-grained encoding’s advantage over other strategies for encoding the metadata.", // abstract
				            null,
				            // "https://arxiv.org/abs/2004.13625", // arXiv_link
				            // "https://github.com/xinyadu/doc_event_role", // code
				        )
				        document.write("</ul>")
				</script>

    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
    <script src="assets/style-3.js"></script>
</html>
